{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create A YouTube Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape From Social Blade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_url = r\"https://socialblade.com/youtube/top/trending/bottom-500-channels-30-days/most-unsubscribed\"\n",
    "good_url = r\"https://socialblade.com/youtube/top/trending/top-500-channels-30-days/most-subscribed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_style(div, style_dict):\n",
    "    \"\"\"Search a HTML String for a given style\"\"\"\n",
    "    div_style = div.get_attribute_list(\"style\")[0]\n",
    "    if div_style:\n",
    "        style_pair_list = [[j.strip() for j in i.strip().split(\":\")] for i in div_style.split(\";\") if i.strip()]\n",
    "        c_div_style_dict = {pair[0]:pair[1] for pair in style_pair_list}\n",
    "        for k,v in style_dict.items():\n",
    "            if k not in c_div_style_dict:\n",
    "                return False\n",
    "            if v != c_div_style_dict[k]:\n",
    "                return False\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_details(row):\n",
    "    \"\"\"Pass row of HTML from SocialBlade Table, return Tuple of Name, Subs, Views\"\"\"\n",
    "    name = row.find_all(\"a\")[0].string\n",
    "    stats = [c_div for c_div in row.find_all(\"div\") if search_style(c_div, {\"width\":\"150px\"})]\n",
    "    subs, views = [int(c_stat.text.strip().replace(\",\",\"\").replace(\"--\", \"0\")) for c_stat in stats]\n",
    "    return name, subs, views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_socialblade(url):\n",
    "    \"\"\"Pass SpcialBlade URL, return pandas DataFrame of data\"\"\"\n",
    "    # TargetStyle is the normal width of the SocialBlade data table\n",
    "    target_style = {\"width\":\"860px\"}\n",
    "    \n",
    "    results = requests.get(url)\n",
    "    content = results.content\n",
    "    soup = bs(content, \"html.parser\")\n",
    "    divs = soup.find_all(\"div\")\n",
    "    rows = [c_div for c_div in divs if search_style(c_div, target_style)][2:]\n",
    "    table_data = [get_details(c_row) for c_row in rows]\n",
    "    return pd.DataFrame(table_data, columns = [\"Name\", \"Subs\", \"Views\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Names for NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(string, valid_chars = None, max_len=36):\n",
    "    \"\"\"Convert a string into a matrix of one-hot encoded character vectors\"\"\"\n",
    "    if not valid_chars:\n",
    "        letters = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "        letters += letters.upper()\n",
    "        special_chars = r\" !@#$%^&*()_+-={}[]:;<,>.?/\\`~'\" + '\"'\n",
    "        numbers = \"\".join([str(i) for i in range(10)])\n",
    "        valid_chars = letters + special_chars + numbers\n",
    "    valid_char_ct = len(valid_chars)\n",
    "    \n",
    "    output = []\n",
    "    for i in string:\n",
    "        c_letter = np.zeros(valid_char_ct)\n",
    "        c_letter[valid_chars.index(i)] = 1\n",
    "        output.append(c_letter)\n",
    "    while len(output)<max_len:\n",
    "        output.append(np.zeros(valid_char_ct))\n",
    "    return np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(input_matrix, valid_chars = None):\n",
    "    \"\"\"Convert a matrix of one-hot encoded character vectors into a string\"\"\"\n",
    "    if not valid_chars:\n",
    "        letters = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "        letters += letters.upper()\n",
    "        special_chars = r\" !@#$%^&*()_+-={}[]:;<,>.?/\\`~'\" + '\"'\n",
    "        numbers = \"\".join([str(i) for i in range(10)])\n",
    "        valid_chars = letters + special_chars + numbers\n",
    "    output = \"\"\n",
    "    for i in input_matrix:\n",
    "        try:\n",
    "            index = np.where(i==1)[0][0]\n",
    "        except IndexError:\n",
    "            return output\n",
    "        output += valid_chars[index]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_chars():\n",
    "    letters = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    letters += letters.upper()\n",
    "    special_chars = r\" !@#$%^&*()_+-={}[]:;<,>.?/\\`~'\" + '\"'\n",
    "    numbers = \"\".join([str(i) for i in range(10)])\n",
    "    return letters + special_chars + numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myData:\n",
    "    valid_chars = valid_chars()\n",
    "    def __init__(self, urls = [], train_pct=.8, filter_df = True):\n",
    "        for index, url in enumerate(urls):\n",
    "            if index == 0:\n",
    "                self.data = get_socialblade(url)\n",
    "            else:\n",
    "                self.data = pd.concat([self.data, get_socialblade(url)])\n",
    "        if filter_df:\n",
    "            self.data = self.data[[all([i in self.valid_chars for i in name]) for name in self.data[\"Name\"]]]\n",
    "        self.data[\"encoded\"] = self.data.apply(lambda row: encode(row[\"Name\"]), axis=1)\n",
    "        self.train = self.data.sample(frac=train_pct)\n",
    "        self.test = self.data[[i not in self.train.index for i in self.data.index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    active_batch_gen = None\n",
    "    \n",
    "    def __init__(self, data, input_col, label_col, batch_size=32):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.label_col = label_col\n",
    "        self.on_epoch_end()\n",
    "        self.indexes = [i for i in range(len(self.data))]\n",
    "        \n",
    "    def __len_(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.data) / self.batch_size))\n",
    "        \n",
    "    def _batch_gen(self):\n",
    "        while True:\n",
    "            self.on_epoch_end()\n",
    "            for index, i in enumerate(index_lst):\n",
    "                yield self.train.iloc[i][self.input_col], self.train.iloc[i][self.label_col]\n",
    "                \n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __data_generation(self):\n",
    "        'Generate one batch of data'\n",
    "        if not self.active_batch_gen:\n",
    "            self.active_batch_gen = self._batch_gen(self.label_col)\n",
    "        \n",
    "        input_lst = []\n",
    "        label_lst = []\n",
    "        for i in range(self.batch_size):\n",
    "            c_input, c_label = next(self.active_batch_gen)\n",
    "            input_lst.append(c_input)\n",
    "            label_lst.append(c_label)\n",
    "        return input_lst, label_lst\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "socialblade_data = myData([good_url, bad_url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generators\n",
    "training_generator = DataGenerator(socialblade_data.train, \"encoded\", \"Views\")\n",
    "validation_generator = DataGenerator(socialblade_data.test, \"encoded\", \"Views\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-f8728ae5a7d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m )\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tf18\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tf18\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tf18\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdo_validation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tf18\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36m__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mbatches\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSequence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \"\"\"\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(36, input_dim=36*94, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit_generator(\n",
    "    generator=training_generator,\n",
    "    validation_data=validation_generator,\n",
    "    use_multiprocessing=True,\n",
    "    workers=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "socialblade_data.data[\"encoded\"].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "socialblade_data.data.iloc[1][\"encoded\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf18)",
   "language": "python",
   "name": "tf18"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
